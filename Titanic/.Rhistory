x1 <- c(2, 2, 6, 4)
x2 <- c(3, 4, 2, 8)
mydata <- data.frame(x1, x2)
mydata$x1
with(mydata, {
mydata$SumX <- x1 + x2
mydata$MeanX <- (x1 + x2) / 2
})
mydata
with(mydata, {
mydata$SumX <- x1 + x2
mydata$MeanX <- (x1 + x2) / 2
})
with(mydata, {
mydata$SumX <<- x1 + x2
mydata$MeanX <<- (x1 + x2) / 2
})
mydata
with(mydata, {
plot(x1, x2)
})
?(cut)
help(cut)
mydates <- as.Date(c("2007-06-22", "2004-02-13"))
mydates
Sys.Date()
date()
help(as.date)
help(as.Date)
x <- c("1jan1960")
z <- as.Date(x, "%d%b%Y")
z
help
help(%in%)
%in%
help(subset)
1 : 4
1: 4
help(mean)
help(cat)
rep(1, 10)
Diabets <- c('Type1', 'Type2')
factor(Diabets)
install.packages(ISLR)
install.packages(MASS)
install.packages(ISLR)
install.packages(ISLR)
install.packages('ISLR')
par(mfrow = c(2, 2))
slices <- c(10, 12, 4, 16, 8)
lbls <- c('US', 'UK', 'Australia', 'Germany', 'France')
pie(slices, labels = lbls, main = "Simple Pie Chart")
pct <- round(slices / sum(slices) * 100)
lbls2 <- paste(lbls, ' ', pct, "%", sep = '')
lbls2
pie(slices, labels = lbls2, col = rainbow(length(lbls2)), main = "Pie Chart with Percentage")
library(plotrix)
pie3D(slices, labels = lbls, explode = 0.1, main = "3D Pie Chart")
mytable <- table(state.region)
mytable
lbls3 <- paste(names(mytable), '\n', mytable, sep = '')
pie(mytable, labels = lbls3, main = "Pie Chart from a Table\n (with sample sizes")
help(hist)
par(mfrow = c(2, 2))
hist{(mtcars$mpg)}
hist(mtcars$mpg)
hist(mtcars$mpg, breaks = 12, col = 'red')
hist(mtcars$mpg, breaks = 12, col = 'red')
rug(jitter(mtcars$mpg))
lines(density(mtcars$mpg), col = 'blue', lwd = 2)
x <- mtcars$mpg
h <- hist(x, breaks = 12, col = 'red')
xfit <- seq(min(x), max(x), length = 40)
yfit <- dnorm(xfit, mean = mean(x), sd = sd(x))
yfit <- yfit * diff(h$mids[1: 2]) * length(x)
lines(xfit, yfit, col = 'blue', lwd = 2)
box()
h&minds
h$mids
help(diff)
d <- density(mtcars$mpg)
polygon(d, col = 'red', border = 'blue')
plot(d)
polygon(d, col = 'red', border = 'blue')
help(polygon)
install('sm')
install.packages('sm')
par()
par(mfrow = c(1, 1))
library(sm)
attach(mtcars)
cyl.f <- factor(cyl, levels = c(4, 6, 8), labels = c('4 cylinder', '6 cylinder', '8 cylinder'))
sm.density.compare(mpg, cyl)
sm.density.compare(mpg, cyl.f)
cyl
sm.density.compare(mpg, cyl.f)
cyl
sm.density.compare(mpg, cyl)
par(mfrow = c(1, 1))
library(sm)
attach(mtcars)
cyl.f <- factor(cyl, levels = c(4, 6, 8), labels = c('4 cylinder', '6 cylinder', '8 cylinder'))
sm.density.compare(mpg, cyl)
colfill <- c(2: (1 + length(levels(cyl.f))))
legend(locator(1), levels(cyl.f), fill = colfill)
cyl.f
box(mpg ~ cyl, data = mtcars, notch = TRUE, varwidth = TRUE)
boxplot(mpg ~ cyl, data = mtcars, notch = TRUE, varwidth = TRUE)
install.packages('vioplot')
library(vioplot)
within(mtcars,{
x1 <- mpg[cyl == 4]
x2 <- mpg[cyl == 6]
x3 <- mpg[cyl == 8]
})
with(mtcars,{
x1 <<- mpg[cyl == 4]
x2 <<- mpg[cyl == 6]
x3 <<- mpg[cyl == 8]
})
within(mtcars,{
x1 <- mpg[cyl == 4]
x2 <- mpg[cyl == 6]
x3 <- mpg[cyl == 8]
})
vioplot(x1, x2, x3)
library(Hmisc)
myvars <- c('mpg', 'hp', 'wt')
describe(mtcars[myvars])
install.packages('pastecs')
library(pastecs)
myvar <- c('mpg', 'hp', 'wt')
stat.desc(mtcars[myvar])
install.packages('psych')
install.packages('doBy')
library(vcd)
install.packages('vcd')
install.packages("vcd")
library(vcd)
head(Arthritis)
install.packages('gmodels')
help(addmargins)
t_value <- 2.142884
2 * pt(t_value, 43)
2 * (1 - pt(t_value, 43))
qt(0.975, 43)
t_value <- 2.1429
pt(t_value, 43)
y <- c(40, 41, 43, 42, 44, 42, 43, 42)
x <- c(0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0)
m1 <- lm(y ~ x)
summary(m1)
anova(m1)
x_bar <- mean(x)
x_bar
ssx <- sum((x - x_bar) ** 2)
ssx
1.2877 / 10.5
sqrt(0.122638)
0.8842 * 0.8842
10.5 * 10.5
1.2877 * (1 / 8 + 110.25 / 10.5)
2.25 ** 2
1.2877 * (1 / 8 + 5.0625 / 10.5)
x <- c(0.3, 1.4, 1.0, -0.3, -0.2, 1.0, 2.0, -1.0, -0.7, 0.7)
y <- c(0.4, 0.9, 0.4, -0.3, 0.3, 0.8, 0.7, -0.4, -0.2, 0.7)
m1 <- lm(y ~ x)
summary(m1)
setwd("~/Coding/R")
census.data <- read.table("census.csv", header = T)
head(census.data)
census.data <- read.csv("census.csv", header = T)
head(census.data)
census.sample <- census.data[is.na(census.data) == FALSE]
head(census.sample)
census.sample <- census.data[is.na(census.data$outcome) == FALSE,]
head(census.sample)
census.prediction <- census.data[is.na(census.data$outcome) == TRUE,]
head(census.prediction)
census.data <- read.csv("census.csv", header = T)
with(census.data, {
educ <<- factor(educ)
status <<- factor(status)
race <<- factor(race)
gender <<- factor(gender)
})
census.sample <- census.data[is.na(census.data$outcome) == FALSE,]
census.prediction <- census.data[is.na(census.data$outcome) == TRUE,]
head(census.sample)
character(census.data$educ)
character(census.data$age)
help(character)
is.factor(census.data$educ)
logistic.fit = glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
summary(logistic.fit)
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
summary(logistic.fit)
library(ISLR)
set.seed(1)
library(boot)
cv.err <- cv.glm(census.sample, logistic.fit)
dim(census.sample)
library(MASS)
help(qda)
qda.fit <- qda(outcome ~ age + educ + status + race + gender + hrs, data = census.sample)
summary(qda.fit)
predict(qda, newdata = data.frame(age = 10, educ = 'Bachelor', Status = 'Divorced', race = 'white', gender = 'Female'))
head(census.sample)
predict(qda, newdata = census.sample[1, 1 - 7], gender = 'Female'))
predict(qda, newdata = census.sample[1, c(1-7)], gender = 'Female'))
predict(qda, newdata = census.sample[1, c(1, 2, 3, 4, 5, 6)], gender = 'Female'))
predict(qda, newdata = census.sample[1, c(1, 2, 3, 4, 5, 6)])
predict(qda, newdata = census.sample[1, 1 : 6])
predict(qda, census.sample[1, 1 : 6])
predict(qda, census.sample[, 1:6])
predict(qda.fit, census.sample[, 1:6])
predict(qda.fit, census.sample[1, 1:6])
predict(qda.fit, census.sample[1:2, 1:6])
qda.class <- predict(qda.fit, census.sample[, 1:6])$class
table(qda.class, census.sample[, 7])
mean(qda.calss == census.sample[, 7])
mean(qda.class == census.sample[, 7])
logistic.fit <- predict(logistic.fit, census.sample[, 1:6])$class
predict(logistic.fit, census.sample[, 1:6])
predict(logistic.fit, census.sample[1, 1:6])
predict(logistic.fit, census.sample[1:2, 1:6])
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
predict(logistic.fit, census.sample[1:2, 1:6])
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = "binomial")
predict(logistic.fit, census.sample[1:2, 1:6])
predict(logistic.fit, census.sample[1:10, 1:6])
predict(logistic.fit, census.sample[1:10, 1:6], type = 'response')
logistic.value <- predict(logistic.fit, census.sample[, 1:6], type = 'response')
mean(logistic.value)
logistic.value[logistic.value >= .5] = 1
logistic.value[logistic.value < .5] = 0
table(logistic.value, census.sample[, 7])
mean(logistic.value == census.sample[, 7])
step(logistic.fit, direction = "both")
step(logistic.fit, direction = "backward")
logistic.value <- predict(logistic.fit, census.prediction[, 1:6])
head(logistic.value)
logistic.value <- predict(logistic.fit, census.prediction[, 1:6], type = "response")
head(logistic.value)
logistic.value[logistic.value > .5] <- 1
logistic.value[logistic.value < .5] <- 0
head(logistic.value)
dim(logistic.value)
census.prediction$outcome <- logistic.value
output.data <- rbind(census.sample[, 7: 8], census.prediction[, 7: 8])
head(output.data)
output.data <- output.data[, c('id', 'outcome')]
head(output.data)
output.data <- output.data[order(output.data$id),]
head(output.data)
View(output.data)
predict(qda.fit, census.prediction[,1: 6])$class
predict(qda.fit, census.prediction[1,1: 6])$class
head(census.prediction)
predict(qda.fit, census.prediction[2,1: 6])$class
predict(qda.fit, census.prediction[3,1: 6])$class
predict(qda.fit, census.prediction[1:6,1: 6])$class
write.table(output.data, "hw5.txt")
write.table(output.data, "hw5.txt", sep = '\t')
View(output.data)
write.table(output.data, "hw5.txt", sep = '\t')
help(write.table)
dim(output.data)
write.table(output.data, "hw5.txt", sep = '\t')
write.table(output.data, "hw5.txt", col.names = c("id", "outcome"), row.names = output.data[,1] sep = '\t')
write.table(output.data, "hw5.txt", col.names = c("id", "outcome"), row.names = output.data[,1], sep = '\t')
write.table(output.data, "hw5.csv")
write.table(output.data, "hw5.csv", sep = '\t')
View(output.data)
write.csv(output.data, "hw5.csv")
input.data <- read.table("hw5.txt", header = T)
head(input.data)
View(census.data)
View(census.prediction)
census.data <- read.csv("census.csv", header = T)
with(census.data, {
educ <<- factor(educ)
status <<- factor(status)
race <<- factor(race)
gender <<- factor(gender)
})
census.sample <- census.data[is.na(census.data$outcome) == FALSE,]
census.prediction <- census.data[is.na(census.data$outcome) == TRUE,]
logistic.fit <- glm(outcome ~ age + educ + status + race + gender + hrs, data = census.sample, family = binomial)
logistic.value <- predict(logistic.fit, census.prediction[, 1:6], type = 'response')
logistic.value[logistic.value > .5] <- 1
logistic.value[logistic.value < .5] <- 0
output.data <- cbind(logistic.value, census.prediction[,8])
View(output.data)
write.table(logistc.value, 'output.txt', sep = '\t')
write.table(logistic.value, 'output.txt', sep = '\t')
write.table(logistic.value, 'output.txt', sep = '\t', colname = c('id', 'outcome'))
write.table(output.data, 'output.txt', sep = '\t')
output <- output[,c(2,1)]
output.data <- output.data[,c(2,1)]
write.table(output.data, 'output.txt', sep = '\t')
dim(output.data)
names(output.data) <- c('id', 'outcome')
write.table(output.data, 'output.txt', sep = '\t')
write.table(output.data, 'output.txt', sep = '\t')
library(FSelector)
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR()
updateR()
??updateR
library(installr)
install.packages('dplyr')
help(dplyr)
install.packages('knitr')
setwd("~/Project/Kaggle/Titanic")
#This is possible feature engineerings of Kaggle Titanic
#Load train data
train.data <- read.csv('train.csv', stringsAsFactors = FALSE)
test.data <- read.csv('test.csv', stringsAsFactors = FALSE)
#combine the two data set's features, then do feature engineering
feature.data <- rbind(train.data[,c(-2)], test.data)
#Inspect train data and clean train data
str(feature.data)
feature.data$Pclass <- as.factor(feature.data$Pclass)
feature.data$Sex <- as.factor(feature.data$Sex)
feature.data$Embarked <- as.factor(feature.data$Embarked)
#Transfer original feature name into useful feature Title
feature.data$Title <- sapply(feature.data$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][2]})
feature.data$Title <- sub(' ', '', feature.data$Title)
feature.data$Title[feature.data$Title %in% c('Mme', 'Mlle')] <- 'Mlle'
feature.data$Title[feature.data$Title %in% c('Capt', 'Don', 'Major', 'Sir')] <- 'Sir'
feature.data$Title[feature.data$Title %in% c('Dona', 'Lady', 'the Countess', 'Jonkheer')] <- 'Lady'
feature.data$Title <- factor(feature.data$Title)
#Combine features SibSp and Parch into FamilySize, reduce dimensions
feature.data$FamilySize <- feature.data$SibSp + feature.data$Parch + 1
#Find the people in the same family, with the same Surname and concerning the familysize
feature.data$Surname<- sapply(feature.data$Name, FUN=function(x) {strsplit(x, split='[,.]')[[1]][1]})
feature.data$FamilyID <- paste(as.character(feature.data$FamilySize), feature.data$Surname, sep="")
feature.data$FamilyID[feature.data$FamilySize <= 2] <- 'Small'
famIDs <- data.frame(table(feature.data$FamilyID))
famIDs <- famIDs[famIDs$Freq <= 2,]
feature.data$FamilyID[feature.data$FamilyID %in% famIDs$Var1] <- 'Small'
feature.data$FamilyID <- factor(feature.data$FamilyID)
#Fill in the value of missing data in Fare
feature.data[is.na(feature.data$Fare),]$Fare <- mean(feature.data[feature.data$Pclass == 3,]$Fare, na.rm = TRUE)
#Fill in the value of missing data in Age by Title
fill_in_age_by_title <- function(obs) {
if(is.na(obs['Age'])){
title <- obs['Title']
age <- mean(feature.data[feature.data$Title == title,]$Age, na.rm = TRUE)
return(age)
}else {
return(obs['Age'])
}
}
feature.data$Age <- apply(feature.data, 1, FUN=fill_in_age_by_title)
feature.data$Age <- as.numeric(feature.data$Age)
#Extract Cabin Num and deck from Cabin
feature.data$CabinNum <- sapply(feature.data$Cabin, function(x) strsplit(x, '[A-Z]')[[1]][2])
feature.data$CabinNum <- as.numeric(feature.data$CabinNum)
feature.data$Deck <- sapply(feature.data$Cabin, function(x) strsplit(x, '')[[1]][1])
#Cabin Num 1-50 as Front, 50-100 as Middle, >100 as End
feature.data$CabinPos <- NA
feature.data$CabinPos[feature.data$CabinNum<50]<-'Front'
feature.data$CabinPos[feature.data$CabinNum>=50 & feature.data$CabinNum<100]<-'Middle'
feature.data$CabinPos[feature.data$CabinNum>=100]<-'End'
feature.data$CabinPos <- as.factor(feature.data$CabinPos)
#If Cabin Num is odd, on the right, else, on the left
feature.data$CabinLoc <- NA
feature.data$CabinLoc[feature.data$CabinNum %% 2 == 0] <- 'left'
feature.data$CabinLoc[feature.data$CabinNum %% 2 != 0] <- 'right'
feature.data$CabinLoc <- as.factor(feature.data$CabinLoc)
# Weik below
#Select feature
feature<- c("Pclass","Age","Sex","Fare","Parch","SibSp","Embarked","CabinPos","CabinLoc")
new.data<- feature.data[,feature]
#Applying RF
library(randomForest)
train.y<- as.factor(train.data$Survived)
train.x<- new.data[c(1:nrow(train.data)),]
test<- new.data[-c(1:nrow(train.data)),]
#selcet data with cabin information
location_train<- which(is.na(train.x$CabinPos) == TRUE)
location_test<- which(is.na(test$CabinPos) == TRUE)
# model one: with cabin information
train.x1<- train.x[-location_train,]
train.y1<- train.y[-location_train]
test1<- test[-location_test,]
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 500, mtry = 6)
mean(rf1$err.rate[,1])
rfpredice1<- predict(rf1, test1)
#model two: without cabin information
feature2<- c("Pclass","Age","Sex","Fare","Parch","SibSp","Embarked")
train.x2<- train.x[location_train,feature2]
train.y2<- train.y[location_train]
test2<- test[location_test,feature2]
set.seed(10)
rf2<- randomForest(train.x2, train.y2,ntree = 500, mtry = 3)
rfpredice2<- predict(rf2, test2)
mean(rf2$err.rate[,1])
View(test)
View(train.x1)
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 1000, mtry = 3)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 500, mtry = 6)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 6)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 5)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 4)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 3)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 7)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 8)
mean(rf1$err.rate[,1])
set.seed(10)
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 9)
mean(rf1$err.rate[,1])
set.seed(10)
rf2<- randomForest(train.x2, train.y2,ntree = 10000, mtry = 3)
mean(rf2$err.rate[,1])
set.seed(10)
rf2<- randomForest(train.x2, train.y2,ntree = 10000, mtry = 2)
mean(rf2$err.rate[,1])
set.seed(10)
rf2<- randomForest(train.x2, train.y2,ntree = 10000, mtry = 4)
mean(rf2$err.rate[,1])
set.seed(10)
rf2<- randomForest(train.x2, train.y2,ntree = 10000, mtry = 5)
mean(rf2$err.rate[,1])
rf1<- randomForest(train.x1, train.y1,ntree = 10000, mtry = 8)
rfpredice1<- predict(rf1, test1)
rf2<- randomForest(train.x2, train.y2,ntree = 10000, mtry = 3)
rfpredice2<- predict(rf2, test2)
View(test2)
test1 <- cbind(test1, rfpredice1)
test2 <- cbind(test2, rfpredice2)
test <- rbind(test1, test2)
View(test1)
result <- rbind(test1$rfpredice1, test2$rfpredice2)
View(result)
rm(result)
View(test1)
View(test1)
ttest2$CabinPos <- NA
test2$CabinPos <- NA
test2$CabinLoc <- NA
test <- rbind(test1, test2)
result <- rbind(test1, test2)
View(test2)
result <- rbind(test1[[rfpredice1]], test2[[rfpredice2]])
result <- rbind(test1[,'rfpredice1'], test2[,'rfpredice2'])
View(result)
name1 <- row.names(test1)
name2 <- row.names(test2)
test.result1 <- cbind(name1, rfpredice1)
test.result2 <- cbind(name2, rfpredice2)
result <- rbind(test.result1, test.result2)
View(result)
result <- result[order(result$name1),]
result <- result[order(result$name1),]
result <- as.data.frame(result)
result <- result[order(result$name1),]
View(result)
result <- result[order(result$name1, decreasing = T),]
View(result)
View(test.data)
result <- result[order(result$name1, decreasing = F),]
View(result)
result <- rbind(test.result1, test.result2, col.name = c('PassengerId', 'Survived'))
result <- as.data.frame(result)
View(result)
names(result)
names(result) <- c('PassengerId', 'Survived')
View(result)
result <- result[order(result$PassengerId, decreasing = F),]
View(result)
result <- rbind(test.result1, test.result2)
result <- as.data.frame(result)
names(result) <- c('PassengerId', 'Survived')
View(result)
result$Survived <- as.integer(result$Survived)
write.csv(result, file = 'solution.csv')
dim(result)
result$Survived <- as.integer(as.character(result$Survived))
write.csv(result, file = 'solution.csv')
write.csv(result, file = 'solution.csv')
str(result)
result$Survived <- result$Survived -1
str(result)
str(test.data)
View(test.data)
View(train.data)
str(train.data)
str(as.factor(Survived))
str(as.factor(train.data$Survived))
View(result)
write.csv(result, file = 'solution.csv')
